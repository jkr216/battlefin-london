---
title: "Import Wrangle Explore"
output:
  html_document:
    df_print: paged
---

### What is R and RStudio? 

R is an open-source statistical programming language that is growing very fast in the world of data science. 

To download R, go to: 

https://cloud.r-project.org

and then click on the link for either Mac, Windows or Linux depending on your computer. 

To install RStudio, go to: 

http://www.rstudio.com/download

RStudio is an integrated development environment (or IDE) for R programming. It makes writing and running R code more fun. 

If all of that is a bit confusing, have a look at this section from *R for Data Science*: 

r4ds.had.co.nz/introduction.html#prerequisites


### Packages

R the programming language consists of base R and the packages that have been built on top of it. Once you have downloaded base R onto your computer and installed RStudio, you need to install the packages we will be using for this workshop.

To install a package on your computer, run `install.packages("name of package")`. To use that package, place `library(name of package)` at the top of your R script or RMarkdown file and run it.

Here are the commands to get the packages for today's workshop.


### Load the packages
 

```{r setup, message = FALSE, warning = FALSE}
# I have already loaded up these packages so we don't have to wait. 
# If you were starting this project fresh on a new computer, would need to remove the 
# '#' from each line and then run the lines of code to install the packages.

# install.packages("tidyverse")
# install.packaged("highcharter")
# install.packages("tidyquant")
# install.packages("tibbletime")
# install.packages("tidymodels")
# install.packages("timetk")
# install.packages("corrr")
# install.packages("plotly")
# install.packages("scales")
# install.packages("readxl")

# or

# 
# for (pkg in c('tidyquant', 'tidyverse', 'plotly', 'highcharter', 'timetk', 'corrr', 'scales', 'tidymodels', 'tibbletime', 'readxl')) 
#   if (!requireNamespace(pkg)) install.packages(pkg)

library(tidymodels)
library(tidyverse) 
library(tidyquant)
library(timetk)
library(tibbletime)
library(highcharter)
library(readxl)
library(corrr)
library(scales)
library(plotly)

knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA)
```


### Our data for today

Our data for today is price and volume data for several ETFs 

    + "SPY"
    + "EFA"
    + "IJS"
    + "EEM"
    + "AGG"
    + "TLT"
    + "VNQ"
    + "UUP"

How, why, where did it come from? Important to document this or at least mention it in a comment or note to self.

Often this will involve grabbing data from internal databases, or from a repository set up by a vendor, or from someone emailing us excel and csv files.

For today, we will import one local excel file, one local csv file and later will look at how to unzip csv files that are publicly available on the internet.

Before getting to code, click on the file and notice how to use the `Import Dataset` button at the top right. This can be a huge time saver and it generates code for us!

Always, always, paste the full code into the script. Future you will thank past you.

```{r}
library(readxl)

# why did I name it 'tibble'? what's a 'tibble'? 
prices_tibble <- 
  read_excel("prices.xlsx") %>% 
  mutate(date = ymd(date))

#View(prices_tibble)
  
prices_tibble %>% 
  tail()
```

Let's get data from a csv format. People love to email around csv's and excel files! 

```{r}
library(readr)
volume_tibble <- 
  read_csv("volume.csv") %>% 
  mutate(date = ymd(date))

#View(volume_tibble)
  
volume_tibble %>% 
  slice(1)

volume_tibble %>% 
  colnames()
```

### What's that weird `%>%`?

This is called the 'pipe' operator. It chains together our functions so we don't have to create new objects each time we do something. It will appear dozens of times today and by the end you'll be tired of seeing it. We can think of this as reading `and then`, it tells the code to keep processing and moving to the next function. 

It makes code more readable and logical, and it saves us from having to create new variable at each line.

### Tidy versus wide data

What is tidy data? Why is it valuable? 

There are three interrelated rules which make a dataset tidy:

    + Each variable must have its own column.
    + Each observation must have its own row.
    + Each value must have its own cell.
    
Simple definition of tidy data - it took Hadley years!
    
r4ds.had.co.nz/tidy-data.html

Converting from wide to tidy is not intuitive. It takes practice and trial/error (at least, it took me a lot of practice and trial/error).


### Let's wrangle

Key functions:
`gather()`, `spread()`, `group_by()`, `slice()`, `mutate()`, `select()`

```{r}
tidy_prices <-
prices_tibble %>% 
  gather(symbol, price, -date) %>% 
  group_by(symbol)

```

Use `slice()` to choose rows and `select()` to choos columns.

```{r}
tidy_prices %>% 
  select(symbol, price) %>% 
  slice(1:3)
```


Notice how `slice(1:3)` grabbed the first 3 rows of each group, it respected our `group_by()`. I use this as a way to peek at the first few rows of each group, to make sure nothing weird jumps out at the beginning.

Let's repeat this process for our volume data.

```{r}

tidy_volume <-
volume_tibble %>% 
  gather(symbol, volume, -date) %>% 
  group_by(symbol)

tidy_volume %>% 
  slice(1:3)
```

We have price data and volume data in two separate tibbles. 

Let's `join` them together into one data set. Have a quick look and notice they have common columns, `date` and `symbol`. We can join on those.

```{r}

price_volume <- 
tidy_prices %>% 
  left_join(tidy_volume, by = c("date", "symbol"))

price_volume %>% 
  slice(1:3)

# what if want to write this data back an excel file, because your colleague, boss, collaborator wants that format. 
# Use this
# readr::write_excel_csv()
```


### data visualization

Let's start with `ggplot2`

A little background

    + part of the tidyverse and works well with tidy data
    + grammar of graphics
    + most popular data vis package
    + layers and geoms
    
Why visualize now? All we did was import some data: 

   + find errors or missing data now
   + start getting to know our data
   
Let's create a line chart of prices, first on one chart, then with an individual panel for each symbol.

```{r}
price_volume %>%
  ggplot(aes(x = date, y = price, color = symbol)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~symbol, scales = "free")
```

Let's do the same with volume data.

```{r}
price_volume %>% 
  ggplot(aes(x = date, y = volume, color = symbol)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~symbol, scales = "free")
```

How about a scatter plot?

```{r}
price_volume %>%
  ggplot(aes(x = volume, y = price, color = symbol)) +
 # ggplot(aes(x = date, y = price, color = symbol)) +
  geom_point() +
 theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~symbol, scales = "free")
```

The key to `ggplot` is the different `geom_` layers. We can different layers, shapes and aesthetics.

### Interactve charting with plotly

The magical `ggplotly()` function makes it fast to get started with plotly. We can convert our `ggplots` to interactive. Not perfect, but efficient.

```{r}
ggplotly(
price_volume %>%
  ggplot(aes(x = date, y = price, color = symbol)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~symbol, scales = "free")
)
```

### Interactve charting with highcharter

What is highcharter? An R package that wraps a javascript package - also called an html widget. 

htmlwidgets.org - JavaScript libraries that have been ported to R. The ecosystem keeps growing and data visualization is becoming part of the skill stack.

```{r}
price_volume %>%
  hchart(., hcaes(x = date, y = price, group = symbol),
         type = "line") %>% 
  hc_title(text = "Daily Prices") %>% 
  hc_tooltip(pointFormat = "{point.symbol}: ${point.price: .2f}")
```



### Fama French Data

What if we wish to bring in data from an outside source, like an alternative data provider, and mash it together with our price volume data? It's data from a different source, probably in a weird format. We need to import it, then get it into shape to be used with our other data. Very often that will mean coercing dates into a common format. We will work with Fama French data, which is hosted on their website in zipped csv files.
     
We first need the address where the zip files live
     
```{r}
# Homepage URL: 
# http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html#Research

factors_data_address <- 
"http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/Global_5_Factors_Daily_CSV.zip"
```

Next we download them to a temporary file location.

```{r}

temp <- tempfile()

download.file(
  # location of file to be downloaded
  factors_data_address,
  # where we want R to store that file
  temp, 
  quiet = TRUE)
```

Unzip, store the contents as `file` and extract the file name with `file$Name`.

```{r}
file <- unzip(temp, list = TRUE)

csv_file <- 
  file$Name

Global_5_Factors_Daily <- 
  read_csv(unz(temp, csv_file), 
    col_types = cols(X1 = col_date(format = "%Y%m%d")), 
    skip = 6) %>% 
  rename(date = X1, MKT = `Mkt-RF`) %>%
  mutate_if(is.numeric, funs(. / 100)) %>% 
  select(-RF)


Global_5_Factors_Daily %>% 
  tail()
```
 
We have a column called date, just as we do in our `prices_volume` tibble. Let's join again!

```{r}
funds_ff_joined <-
price_volume %>% 
  left_join(Global_5_Factors_Daily, by = "date") %>% 
  group_by(symbol) %>% 
  na.omit()

funds_ff_joined %>% 
  tail()
```

We now have a tibble, of daily fund prices and volumes, and Fama French factors, from March 3, 2007 through April 4, 2019. 


### Transform data from daily prices to daily returns

Key functions: 
`group_by()`, `mutate()`, `select()`, `slice()`, `filter()`

Thus far, we've been tidying and joining, not transforming.  

Let's create a new returns column, which we might want to model/predict, and new features that could be used in that modeling. We'll use the `mutate()` function for that. Probably the function I find myself using most frequently.

Start with a simple transformation of daily prices to log returns. Not complicated but now we're changing this data, and that's an important step. 


```{r}
funds_ff_returns <- 
  funds_ff_joined %>% 
  mutate(daily_returns = price/lag(price) - 1)

funds_ff_returns %>% 
  select(date, daily_returns) %>% 
  slice(1:3)
```

### Getting our data ready for modeling

Now let's create some predictor columns, perhaps we want to incorporate a normalized volume and price trend. We can calculate the rolling 50-day and 200-day means and the rolling z-scored volume.

First, let's create some rolling functions using the amazing `rollify` from the `tibbletime` package!

```{r}
library(tibbletime)

sma_50 <- rollify(mean, window = 50)
sma_200 <- rollify(mean, window = 200)

sd_50 <- rollify(sd, window = 50)
```

Now we combine our custom rolling functions with `mutate()` to create new columns.

Luckily R has also some fantastic finance pacakges with helpful functions already constructed. 

The `TTR` package lets us add technical indicators. Let's add `MACD` and `CCI`. 

We use `tq_mutate()` to add those columns and indicators. We can do all of this in one piped flow, without creating new objects each time.

```{r}
funds_ff_full <- 
funds_ff_returns %>% 
  mutate(
    price_sma_50 = sma_50(price),
    price_sma_200 = sma_200(price),
    sma_signal = if_else(price_sma_50 > price_sma_200, 1, 0),
    scaled_vol = (volume - sma_50(volume))/sd_50(volume)) %>% 
  tq_mutate(select     = price, 
            mutate_fun = MACD, 
            col_rename = c("MACD", "Signal")) %>% 
  tq_mutate(select     = price, 
            mutate_fun = CCI, 
            col_rename = "CCI",
            n = 20) %>% 
  na.omit()

save("funds_ff_full.RData")
```

### Visualizations

We could head straight to modeling this data and extracting predictions but I like to build a few visualizations first. Who knows what sorts of patterns might emerge?

SMA 50, SMA 200 and scaled volume for EEM and SPY

```{r}
funds_ff_full %>% 
  filter(symbol == "EEM" | symbol == "SPY") %>%
  #ungroup() %>% 
  select(date, scaled_vol, price_sma_50, price_sma_200) %>% 
  gather(stat, value, -date, -symbol) %>% 
  ggplot(aes(x = date, y = value, color = stat)) +
  geom_line() +
  facet_wrap(~stat + symbol, scales =  "free", ncol = 2) 

```
CCI, MACD and Signal for EEM and SPY

```{r}
funds_ff_full %>% 
  filter(symbol == "EEM" | symbol == "SPY") %>% 
  select(date, CCI, MACD, Signal) %>% 
  gather(stat, value, -date, -symbol) %>% 
  ggplot(aes(x = date, y = value, color = stat)) +
  geom_line() +
  facet_wrap(~stat + symbol, scales =  "free", ncol = 2) 
```


```{r}
funds_ff_full %>% 
#  filter(symbol == "EEM") %>%
  ggplot(aes(x = scaled_vol)) +
  geom_histogram(fill = "cornflowerblue", color = "pink", bins = 60) +
  facet_wrap(~symbol)

```

sma 50, sma 200 and price time series
```{r}

ggplotly(
funds_ff_full %>% 
  #filter(symbol == "IJS") %>%
  select(date, symbol, price, price_sma_200, price_sma_50) %>% 
  ggplot(aes(x = date)) +
  geom_line(aes(y = price), color = "purple", linetype = "dashed", alpha = .3) +
  geom_line(aes(y = price_sma_200), color = "cornflowerblue") +
  geom_line(aes(y = price_sma_50), color = "pink") +
  labs(x = "", y = "price stats") +
  facet_wrap(~symbol, scales = "free")
)
```

